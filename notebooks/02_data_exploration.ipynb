{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell setup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Cấu hình hiển thị\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df = pd.read_csv('../data/processed/student-clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## **Data overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**Basic Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(f\"Overall size: {df.size}\")\n",
    "print(\"Each row represents the information of one student in a specific course\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "**Data Integrity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "print(\"Number of entirely empty rows:\", df.isnull().all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
    "2. sex - student's sex (binary: 'F' - female or 'M' - male)\n",
    "3. age - student's age (numeric: from 15 to 22)\n",
    "4. address - student's home address type (binary: 'U' - urban or 'R' - rural)\n",
    "5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "7. Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "8. Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "12. guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n",
    "13. traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "14. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "15. failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "16. schoolsup - extra educational support (binary: yes or no)\n",
    "17. famsup - family educational support (binary: yes or no)\n",
    "18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "19. activities - extra-curricular activities (binary: yes or no)\n",
    "20. nursery - attended nursery school (binary: yes or no)\n",
    "21. higher - wants to take higher education (binary: yes or no)\n",
    "22. internet - Internet access at home (binary: yes or no)\n",
    "23. romantic - with a romantic relationship (binary: yes or no)\n",
    "24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "25. freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "26. goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "29. health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "30. absences - number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "These grades are related with the course subject, Math or Portuguese:\n",
    "\n",
    "1. G1 - first period grade (numeric: from 0 to 20)\n",
    "2. G2 - second period grade (numeric: from 0 to 20)\n",
    "3. G3 - final grade (numeric: from 0 to 20, output target)\n",
    "4. Subject: Math or Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"G3\"]\n",
    "print(f\"Number of unique values in target variable: {y.nunique()}\\nValues: {np.sort(y.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = y.value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(counts.index, counts.values)\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Target Variable\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## **Numerical Columns Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Distribution & Central Tendency:\n",
    "• What is the distribution shape? (normal, skewed, bimodal, uniform)\n",
    "• Create visualizations: histograms, box plots, density plots,…\n",
    "• Calculate: mean, median, standard deviation\n",
    "'''\n",
    "# Chọn các cột số quan trọng để phân tích\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Tính toán Central Tendency (Mean, Median, Std) & Shape (Skewness)\n",
    "stats_summary = df[numeric_cols].agg(['mean', 'median', 'std', 'skew']).T\n",
    "stats_summary.columns = ['Mean', 'Median', 'Std Dev', 'Skewness']\n",
    "\n",
    "def determine_shape(skew_val):\n",
    "    if -0.5 <= skew_val <= 0.5:\n",
    "        return \"Symmetrical (Normal-like)\"\n",
    "    elif skew_val > 0.5:\n",
    "        return \"Right Skewed (Positively)\"\n",
    "    else:\n",
    "        return \"Left Skewed (Negatively)\"\n",
    "\n",
    "stats_summary['Distribution Shape'] = stats_summary['Skewness'].apply(determine_shape)\n",
    "stats_summary = stats_summary.sort_values(by='Skewness')\n",
    "\n",
    "print(\"--- BẢNG THỐNG KÊ MÔ TẢ & HÌNH DÁNG PHÂN PHỐI ---\")\n",
    "display(stats_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc ra những cột bị lệch kèm distrubution shape\n",
    "skewed_cols = stats_summary[stats_summary['Distribution Shape'] != \"Symmetrical (Normal-like)\"]\n",
    "print(\"--- CÁC CỘT BỊ LỆCH VÀ HÌNH DÁNG PHÂN PHỐI ---\")\n",
    "display(skewed_cols)\n",
    "\n",
    "# Chỉ lấy các biến không có phân phối chuẩn\n",
    "non_normal_cols = stats_summary[stats_summary['Distribution Shape'] != 'Symmetrical (Normal-like)'].index.tolist()\n",
    "\n",
    "# Trực quan hóa: Histogram cho các biến không chuẩn\n",
    "n = len(non_normal_cols)\n",
    "plots_per_fig = 4\n",
    "for i in range(0, n, plots_per_fig):\n",
    "    cols_to_plot = non_normal_cols[i:i+plots_per_fig]\n",
    "    n_subplots = len(cols_to_plot)\n",
    "    nrows = 2\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 7))\n",
    "    axes = axes.flatten()\n",
    "    for j, col in enumerate(cols_to_plot):\n",
    "        ax = axes[j]\n",
    "        sns.histplot(df[col], kde=True, bins=10, color='skyblue', edgecolor='black', ax=ax)\n",
    "        ax.axvline(df[col].mean(), color='red', linestyle='--', label='Mean')\n",
    "        ax.axvline(df[col].median(), color='green', linestyle='-', label='Median')\n",
    "        ax.set_title(f'{col} ({stats_summary.loc[col, \"Distribution Shape\"]})')\n",
    "        ax.legend()\n",
    "    # Ẩn subplot thừa nếu số biến không chia hết cho 4\n",
    "    for k in range(n_subplots, nrows * ncols):\n",
    "        fig.delaxes(axes[k])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Dựa vào kết quả trực quan, những cột cần chuyển đổi độ lệch là:\n",
    "- **Thời gian học (`studytime`)** - Right Skewed: Đa số học ít giờ, ít học sinh học nhiều giờ\n",
    "- **Vắng mặt (`absences`)** - Right Skewed: Đa số vắng ít, ít học sinh vắng nhiều\n",
    "- **famrel** - Right Skewed: Đa số học sinh có mối quan hệ gia đình tốt, ít học sinh có mối quan hệ gia đình kém\n",
    "- **Thời gian du lịch (`traveltime`)** - Right Skewed: Đa số học sinh có thời gian đi lại ngắn, ít học sinh có thời gian đi lại dài\n",
    "- **Lần rớt môn trước (`failures`)** - Right Skewed: Đa số học sinh không rớt, ít học sinh rớt nhiều lần\n",
    "- **Dalc và Walc (`Dalc`, `Walc`)** - Right Skewed: Đa số học sinh uống ít, ít học sinh uống nhiều\n",
    "- **Điểm G3 (`G3`)** - Left Skewed nhẹ: Đa số điểm cao, ít học sinh điểm thấp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Range & Outliers:\n",
    "• What are the minimum and maximum values?\n",
    "• Are min/max values reasonable, or do they indicate errors?\n",
    "• Identify outliers using box plots, IQR method, or z-scores\n",
    "• Are outliers genuine extreme values or data entry errors?\n",
    "'''\n",
    "# 1. Range Analysis: Min & Max Values\n",
    "# Tính toán min/max cho các cột số\n",
    "range_df = df[numeric_cols].agg(['min', 'max']).T\n",
    "\n",
    "# 2. Outlier Detection using IQR Method\n",
    "# Hàm phát hiện outlier\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return len(outliers), lower_bound, upper_bound, outliers[column].unique()\n",
    "\n",
    "# Phân tích outliers cho từng cột số và lưu vào DataFrame\n",
    "outlier_results = []\n",
    "for col in numeric_cols:\n",
    "    count, lower, upper, unique_outliers = detect_outliers_iqr(df, col)\n",
    "    bounds = f\"{lower:.1f} to {upper:.1f}\"\n",
    "    # Chỉ hiển thị vài giá trị outlier đại diện\n",
    "    if len(unique_outliers) < 10:\n",
    "        outlier_str = str(sorted(unique_outliers))\n",
    "    else:\n",
    "        outlier_str = str(sorted(unique_outliers)[:5]) + \"...\"\n",
    "    outlier_results.append({\n",
    "        'Column': col,\n",
    "        'Count': count,\n",
    "        'Bounds (Min-Max)': bounds,\n",
    "        'Extreme Values Found': outlier_str\n",
    "    })\n",
    "outlier_df = pd.DataFrame(outlier_results)\n",
    "# Gộp hai bảng range_df (min/max) và outlier_df thành một bảng tổng hợp\n",
    "summary_df = range_df.copy()\n",
    "summary_df = summary_df.merge(outlier_df.set_index('Column'), left_index=True, right_index=True, how='left')\n",
    "# Đổi tên cột cho rõ ràng\n",
    "summary_df = summary_df.rename(columns={\n",
    "    'min': 'Min',\n",
    "    'max': 'Max',\n",
    "    'Count': 'Outlier Count',\n",
    "    'Bounds (Min-Max)': 'Outlier Bounds',\n",
    "    'Extreme Values Found': 'Outlier Values',\n",
    "    'Reasonable?': 'Reasonable? (Manual Check)'\n",
    "})\n",
    "print(\"--- BẢNG TỔNG HỢP MIN/MAX & OUTLIER ---\")\n",
    "display(summary_df.sort_values(by='Outlier Count', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f905ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa boxplot chỉ cho các biến có outlier (Outlier Count > 0)\n",
    "outlier_cols = summary_df[summary_df['Outlier Count'] > 0].index.tolist()\n",
    "plots_per_fig = 4\n",
    "n = len(outlier_cols)\n",
    "for i in range(0, n, plots_per_fig):\n",
    "    cols_to_plot = outlier_cols[i:i+plots_per_fig]\n",
    "    n_subplots = len(cols_to_plot)\n",
    "    nrows = 2\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 7))\n",
    "    axes = axes.flatten()\n",
    "    for j, col in enumerate(cols_to_plot):\n",
    "        ax = axes[j]\n",
    "        sns.boxplot(x=df[col], ax=ax, color='skyblue', fliersize=5, boxprops=dict(alpha=0.7))\n",
    "        ax.set_title(f'Boxplot of {col}')\n",
    "        ax.set_xlabel(col)\n",
    "    # Ẩn subplot thừa nếu số biến không chia hết cho 4\n",
    "    for k in range(n_subplots, nrows * ncols):\n",
    "        fig.delaxes(axes[k])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "**Nhận định**\n",
    "1. Về điểm số (G3): Có 53 học sinh bị điểm 0.\n",
    "   ->  Đây có thể không phải lỗi nhập liệu mà là học sinh bỏ thi hoặc rớt môn.\n",
    "   -> Hành động: Cần xem xét mối quan hệ của nhóm này với số buổi vắng (absences).\n",
    "   -> Trung bình số buổi vắng của nhóm điểm 0: 0.00\n",
    "   -> Trung bình số buổi vắng của nhóm điểm > 0: 4.67\n",
    "2. Về tuổi tác: Có 2 học sinh trên 21 tuổi (Max = 22).\n",
    "   -> Nhận định: Hợp lý trong bối cảnh trường trung học (lưu ban hoặc đi học muộn), không phải lỗi.\n",
    "3. Về số buổi vắng (absences): Có 54 học sinh vắng trên 15 buổi (Max = 93).\n",
    "   -> Nhận định: Có thể do nghỉ ốm dài ngày hoặc các lý do cá nhân khác, không phải lỗi.\n",
    "\n",
    "Từ phần **Distribution & Central Tendency**, có thể xem xét chuyển đổi độ lệch (skewness) cho các biến: `famrel`, `studytime`, `absences`, `G3`, `traveltime`, `failures`, `Dalc`, `Walc` để cải thiện phân phối dữ liệu trước khi xây dựng mô hình dự đoán.\n",
    "\n",
    "=> Có thể sử dụng Log Transformation với các biến lệch phải và dùng hàm mũ cho cho các biến lệch trái ở bước tiền xử lý sau này."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## **Categorical Columns Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/student-clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc các cột categorical\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical colums: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Value Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm phân tích\n",
    "def analyze_distrubution_cat_col(colname, df):\n",
    "    print(f\"\\nCATEGORICAL COLUMN: {colname.upper()}\")\n",
    "\n",
    "    unique_count = df[colname].nunique()\n",
    "    print(f\"- Unique value: {unique_count}\")\n",
    "    \n",
    "    print(f\"- Column distribution:\")\n",
    "    val_counts = df[colname].value_counts()\n",
    "    distributions = df[colname].value_counts(normalize= True) * 100\n",
    "    \n",
    "    for val, count in val_counts.head(5).items():\n",
    "        percent = distributions[val]\n",
    "        print(f\"{str(val):<10} | {count:>8} | {percent:>7.2f}%\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    analyze_distrubution_cat_col(col, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization các cột categorical\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(cat_cols) / n_cols)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4 * n_rows))  # Tạo nhiều biểu đồ\n",
    "axes = axes.flatten() # Làm phẳng mảng axes\n",
    "\n",
    "for i, colname in enumerate(cat_cols):\n",
    "    sns.countplot(data=df, x=colname, ax=axes[i], palette=\"cividis\", hue=colname)\n",
    "    \n",
    "    axes[i].set_title(f'Distribution of \\\"{colname}\\\"')\n",
    "    axes[i].set_xlabel('')\n",
    "\n",
    "    for container in axes[i].containers:\n",
    "        axes[i].bar_label(container)\n",
    "\n",
    "# Tắt các ô trống nếu số biểu đồ không lấp đầy lưới\n",
    "for i in range(len(cat_cols), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Cột khá cân bằng: `sex`, `activities`\n",
    "\n",
    "- Cột mất cân bằng cao (`Pstatus`, `schoolsup`, `higher`): `Pstatus = T` (88%), `schoolsup = no` (88%), `higher = yes` (90%) $\\rightarrow$ Những cột này sẽ ít có khả năng phân loại vì không có sự biến thiên mà chỉ thiên về 1 phía. Gây ra Model bias nếu sử dụng làm `Target`\n",
    "\n",
    "- Cột mất cân bằng vừa: các cột còn lại "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra tính nhất quán của các cột\n",
    "for colname in cat_cols:\n",
    "    unique_vals = sorted(df[colname].unique().astype(str))\n",
    "    print(f\"{colname:>10} : {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra có các giá trị bị thiếu hay không\n",
    "missing_vals = df[cat_cols].isnull().sum()\n",
    "percent_missing = missing_vals * 100 / len(missing_vals)\n",
    "print(\"Percent of missing value in categorical columns:\")\n",
    "for val, pct in percent_missing.items():\n",
    "    print(f\"{val:>10} : {pct} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "**Nhận xét:** \n",
    "- Không có cột nào có giá trị bị thiếu, giá trị bất thường\n",
    "\n",
    "- Tuy nhiên, đối với cột `Fjob` ta thấy `health` chỉ chiếm số lượng ít (3.93%) và kích thước mẫu của nhóm khá nhỏ (n = 41) nhưng vẫn đủ ngưỡng tối thiểu để thực hiện các so sánh thống kê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### **Nhận xét chung:** \n",
    "- Các cột dữ liệu category: `school`, `sex`, `address`, `famsize`, `Pstatus`, `Mjob`, `Fjob`, `reason`, `guardian`, `schoolsup`, `famsup`, `paid`, `activities`, `nursery`, `higher`, `internet`, `romantic`, `subject`\n",
    "\n",
    "- Các cột đều bị mất cân bằng dữ liệu (trừ cột `sex`, `activities` khá cân bằng)\n",
    "\n",
    "- Các cột không có các giá trị bất thường, lỗi hay các giá trị hiếm (trừ `Fjob` nhưng nhóm quyết định giữ giá trị hiếm lại mà không gộp chung)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## **Missing Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Dữ liệu không có giá trị missing nào\n",
    "- Labels phân bố không đều, giá trị nằm chủ yếu ở khoảng điểm 8 - 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## **Relationships & Correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Preliminary Patterns:\n",
    "• Calculate correlation matrix for numerical variables\n",
    "• Create correlation heatmap\n",
    "• Identify strongly correlated pairs (positive or negative)\n",
    "• Are there any surprising relationships?\n",
    "'''\n",
    "print(\"--- PHÂN TÍCH TƯƠNG QUAN (CORRELATION ANALYSIS) ---\")\n",
    "\n",
    "# 1. Tính ma trận tương quan (Correlation Matrix)\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# 2. Vẽ Heatmap (Biểu đồ nhiệt)\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool)) # Che một nửa tam giác trên để đỡ rối\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=\".2f\", cmap='Purples', vmin=-1, vmax=1, center=0, linewidths=0.5)\n",
    "plt.title('Ma trận tương quan giữa các biến số (Correlation Heatmap)', fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# 3. Xác định các cặp tương quan mạnh (Strongly Correlated Pairs)\n",
    "print(\"\\n--- CÁC CẶP BIẾN CÓ TƯƠNG QUAN MẠNH (|corr| > 0.5) ---\")\n",
    "\n",
    "# Làm phẳng ma trận và sắp xếp\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "sorted_pairs = corr_pairs.sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "# Lọc bỏ tương quan với chính nó (=1) và các cặp trùng lặp\n",
    "strong_pairs = sorted_pairs[sorted_pairs != 1.0]\n",
    "# Chỉ lấy các cặp có độ lớn tương quan > 0.5\n",
    "strong_pairs = strong_pairs[abs(strong_pairs) > 0.5]\n",
    "# Loại bỏ các cặp trùng lặp (ví dụ A-B và B-A) -> Chỉ giữ lại mỗi cặp 1 lần\n",
    "strong_pairs = strong_pairs[~strong_pairs.index.duplicated(keep='first')]\n",
    "# Lọc thủ công để tránh trùng lặp do unstack (A,B) vs (B,A)\n",
    "seen = set()\n",
    "unique_strong_pairs = {}\n",
    "for idx, val in strong_pairs.items():\n",
    "    pair = tuple(sorted(idx))\n",
    "    if pair not in seen:\n",
    "        seen.add(pair)\n",
    "        unique_strong_pairs[pair] = val\n",
    "\n",
    "# In kết quả\n",
    "if not unique_strong_pairs:\n",
    "    print(\"Không có cặp nào có tương quan mạnh trên 0.5 (ngoại trừ các cột điểm số).\")\n",
    "else:\n",
    "    for (var1, var2), corr_val in unique_strong_pairs.items():\n",
    "        print(f\"- {var1} vs {var2}: {corr_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "**NHẬN XÉT**\n",
    "\n",
    "1. Tương quan mạnh nhất: Giữa các cột điểm `G1`, `G2`, `G3` (0.80 - 0.91). -> Kết quả học tập có tính ổn định cao.\n",
    "2. Tương quan gia đình: Trình độ học vấn của Mẹ (`Medu`) và Cha (`Fedu`) tương quan khá cao (0.64).\n",
    "3. Tương quan thói quen: Uống rượu ngày thường (`Dalc`) và cuối tuần (`Walc`) đi cùng nhau (0.63).\n",
    "4. Mối quan hệ bất ngờ (Surprising):\n",
    "   - `failures` (rớt môn) có tương quan ÂM với G3 (khoảng -0.3 đến -0.4). Rớt càng nhiều, điểm càng thấp -> Hợp lý.\n",
    "   - `studytime` (thời gian học) có tương quan dương yếu với điểm số, nhưng không mạnh như mong đợi.\n",
    "   - `absences` (vắng mặt) gần như KHÔNG tương quan với điểm số (gần 0). -> Vắng nhiều chưa chắc đã học kém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Cross-tabulations:\n",
    "• For important categorical × categorical combinations, create frequency tables\n",
    "• For numerical × categorical combinations, create grouped summary statistics\n",
    "'''\n",
    "print(\"QUAN HỆ GIỮA CÁC BIẾN PHÂN LOẠI (CAT x CAT)\")\n",
    "\n",
    "# Tạo biến 'Pass' (Đậu/Rớt) để phân tích dễ hơn (G3 >= 10 là Đậu theo thang điểm Bồ Đào Nha)\n",
    "df['Pass_Status'] = df['G3'].apply(lambda x: 'Pass' if x >= 10 else 'Fail')\n",
    "\n",
    "# Lấy danh sách các cột categorical (không bao gồm Pass_Status vừa tạo)\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col != 'Pass_Status']\n",
    "\n",
    "print(f\"Các cột phân loại: {cat_cols}\")\n",
    "print(f\"Sẽ phân tích {len(cat_cols)} cột với biến mục tiêu Pass_Status\")\n",
    "\n",
    "# Phân tích tỷ lệ Pass/Fail cho TẤT CẢ các cột categorical quan trọng\n",
    "important_cat_cols = ['sex', 'address', 'Pstatus', 'higher', 'internet', 'romantic']\n",
    "\n",
    "print(\"\\n=== TỶ LỆ PASS/FAIL THEO CÁC BIẾN PHÂN LOẠI ===\")\n",
    "\n",
    "for col in important_cat_cols:\n",
    "    if col in df.columns:\n",
    "        ct_table = pd.crosstab(df[col], df['Pass_Status'], normalize='index') * 100\n",
    "        \n",
    "        # Tính chi-square test để xem có significant không\n",
    "        from scipy.stats import chi2_contingency\n",
    "        chi2, p_value, _, _ = chi2_contingency(pd.crosstab(df[col], df['Pass_Status']))\n",
    "        significance = f\"{col} Có ý nghĩa thống kê\" if p_value < 0.05 else f\"{col} Không có ý nghĩa thống kê\"\n",
    "        print(f\"   Chi-square p-value: {p_value:.4f} -> {significance}\")\n",
    "\n",
    "# Trực quan hóa các mối quan hệ categorical quan trọng\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, col in enumerate(important_cat_cols[:6]):  # Chỉ vẽ 6 cái đầu\n",
    "    if col in df.columns:\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        \n",
    "        # Tính tỷ lệ pass cho mỗi nhóm\n",
    "        pass_rates = df.groupby(col)['Pass_Status'].apply(lambda x: (x == 'Pass').mean() * 100)\n",
    "        \n",
    "        # Vẽ bar chart\n",
    "        bars = plt.bar(pass_rates.index, pass_rates.values, \n",
    "                      color=['lightcoral' if rate < 70 else 'lightblue' for rate in pass_rates.values])\n",
    "        \n",
    "        plt.title(f'Tỷ lệ Pass theo {col}')\n",
    "        plt.ylabel('% Pass')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Thêm số liệu trên cột\n",
    "        for bar, rate in zip(bars, pass_rates.values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1, \n",
    "                    f'{rate:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# • For numerical × categorical combinations, create grouped summary statistics\n",
    "# Chọn các cột phân loại quan trọng để phân tích với các biến số\n",
    "cat_cols = ['sex', 'address', 'famsize', 'Pstatus', 'higher', 'internet', 'romantic']\n",
    "# Xem với các biến số quan trọng\n",
    "numeric_cols = ['G3', 'studytime', 'failures']\n",
    "print(\"THỐNG KÊ NHÓM GIỮA BIẾN SỐ VÀ PHÂN LOẠI (NUMERIC x CAT)\")\n",
    "for cat_col in cat_cols:\n",
    "    print(f\"\\n--- Phân tích theo nhóm cho cột phân loại: {cat_col} ---\")\n",
    "    grouped_stats = df.groupby(cat_col)[numeric_cols].agg(['min','max','mean', 'median', 'std'])\n",
    "    # Hiển thị bảng thống kê nhóm cứ 3 numeric một lần để tránh quá dài\n",
    "    for i in range(0, len(numeric_cols), 3):\n",
    "        display(grouped_stats[numeric_cols[i:i+3]])\n",
    "\n",
    "# Trực quan hóa phân phối biến số theo các biến phân loại (Box Plots)\n",
    "plt.figure(figsize=(15, 5 * len(cat_cols)))\n",
    "for i, cat_col in enumerate(cat_cols):\n",
    "    for j, num_col in enumerate(numeric_cols):\n",
    "        plt.subplot(len(cat_cols), len(numeric_cols), i * len(numeric_cols) + j + 1)\n",
    "        sns.boxplot(x=cat_col, y=num_col, data=df, palette='Set3', legend=False, hue=cat_col)\n",
    "        plt.title(f'Phân phối {num_col} theo {cat_col}')\n",
    "        plt.xlabel(cat_col)\n",
    "        plt.ylabel(num_col)\n",
    "        plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## **Initial Observation and Insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### **Summary**\n",
    "**1. Key observation:**\n",
    "- Sự bất thường của Target (`G3`): điểm số có phân phối gần chuẩn nhưng có 53 trường hợp xuất hiện điểm bằng 0. Kèm theo đó là khi `G3` = 0 thì `absences` = 0, điều này là khá vô lý vì theo hành vi học tập, nếu không nghỉ buổi nào nhưng có `G3` = 0. Bên cạnh đó, ta thấy `G1`, `G2` đa số > 0 nếu `G3` = 0  \n",
    "$\\rightarrow$ Có thể là những học sinh này đã bỏ thi, học lực kém, hoặc do các yếu tố tác động khiến cho `G3` bằng 0\n",
    "\n",
    "- Phân phối lệch của `absences`: bị lệch phải nhiều (Skewness = 3.74). Trung vị là 2 nhưng xuất hiện các outlier rất lớn $\\rightarrow$ Điều này cho thấy việc các học sinh có xu hướng ít nghỉ học, có 1 nhóm nhỏ nghỉ học nhiều.\n",
    "\n",
    "- Sự đồng nhất về nhân khẩu học: có sự mất cân bằng lớn trong các biến: 90% có cha mẹ sống chung (`PStatus` = T), đa số có nguyện vọng học cao hơn (`higher` = yes) và không có tham gia các lớp học thêm (`schoolsup` = no)\n",
    "\n",
    "**2. Data quality issues:**\n",
    "- Một vài cột numerical bị lệch $\\rightarrow$ Cần có các cách xử lý để không ảnh hưởng đến chất lượng mô hình \n",
    "\n",
    "- Imbalanced class: các cột categorical nhưng đã phân tích ở trên `Pstatus`, `higher`, `Fjob` bị mất cân bằng nghiêm trọng $\\rightarrow$ Giảm độ tin cậy khi phân tích hành vi của các nhóm này\n",
    "\n",
    "**3. Necessary preprocessing steps:**\n",
    "- Data Integration: Gộp hai bộ dữ liệu student-mat và student-por. Thêm cột định danh Subject ('mat'/'por') để phân biệt ngữ cảnh môn học.\n",
    "\n",
    "- Data cleaning:\n",
    "    -  Sử dụng *Log Transformation* cho các cột: `studytime`, `absences`, `Walc` và *Power Transformation* cho các cột: `G3`, `famrel` để cải thiện chất lượng mô hình khi dự đoán\n",
    "\n",
    "- Feature Engineering:\n",
    "    - Tạo `Total_alc` dựa vào `Dalc` và `Walc`\n",
    "\n",
    "- Encoding cho các câu hỏi sử dụng Machine Learning: \n",
    "    - Sử dụng **Binary Encoding** cho các biến nhị phân (`school`, `sex`, `address`, `famsize`, ... )\n",
    "    - Sử dụng **One-Hot Encoding** cho các biến có nhiều nhóm (`Mjob`, `Fjob`, `reason`, `guardian`, ... )\n",
    "\n",
    "**4. Interesting patterns could lead to research questions:**\n",
    "- Sự tương quan về quá trình học tập `G1`, `G2`, `G3`: các cặp (`G1`,`G2`), (`G2`, `G3`) có sự tương quan cao $\\rightarrow$ Nếu có học sinh đạt điểm thấp ở đầu kì thì rất có nhiều khả năng giữa kì và cuối kì điểm cũng sẽ thấp theo.\n",
    "\n",
    "### **Red flags**\n",
    "**1. Serious data quality concerns:**\n",
    "- Sự tồn tại của `G3 = 0` với `absences = 0` là mâu thuẫn logic nghiêm trọng có ảnh hưởng đến việc phân tích hoặc sử dụng các mô hình Machine Learning cho nên cần phải cân nhắc vấn đề loại bỏ hay không\n",
    "  \n",
    "**2. Limitations might affect analysis:**  \n",
    "- Việc mất cân bằng dữ liệu sẽ dẫn đến việc các kết luận hoặc báo cáo liên quan đến các nhóm thiểu số trong dataset (như `higher = no` hoặc `Fedu = health`) sẽ có độ tin cậy thấp hơn nhóm đa số"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
